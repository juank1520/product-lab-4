{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (OneHotEncoder, MinMaxScaler)\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from feature_engine.encoding import (OrdinalEncoder)\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from feature_engine.imputation import (AddMissingIndicator, MeanMedianImputer, CategoricalImputer)\n",
    "from feature_engine.encoding import (RareLabelEncoder, OrdinalEncoder)\n",
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Cargamos el data train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "dataX = data.drop('Survived', axis=1)\n",
    "dataY = data['Survived']\n",
    "\n",
    "dataTest = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Configuracion del machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_FEATURES = ['Cabin', 'Name', 'Ticket']\n",
    "MEAN_IMPUTATION = ['Age', 'Fare']\n",
    "MISSING_IMPUTATION = ['Embarked']\n",
    "CATEGORICAL_BINARY = ['Sex']\n",
    "CATEGORICAL_ORDINAL = ['Pclass']\n",
    "CATEGORICAL_NOMINAL = ['Embarked']\n",
    "NUMERICALS_YEO_JOHNSON = ['Age', 'Fare']\n",
    "FEATURES = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Creamos el machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanicPipeline = Pipeline([\n",
    "    #- Drop de variables\n",
    "#     ('drop_features', DropFeatures(features_to_drop=DROP_FEATURES)),\n",
    "    \n",
    "    \n",
    "    #==== IMPUTACIONES ====#\n",
    "    #- Imputacion de variables categoricas\n",
    "    ('missing_imputation', CategoricalImputer(imputation_method='missing', variables=MISSING_IMPUTATION)),\n",
    "    \n",
    "    #- Imputacion de media para variables categoricas\n",
    "    ('mean_imputation', MeanMedianImputer(imputation_method='mean', variables=MEAN_IMPUTATION)),    \n",
    "\n",
    "    \n",
    "    #==== TRANSFORMACION DE VARIABLES NUMERICAS ====#\n",
    "    #- Transformacion de Yeo Johnson\n",
    "    ('Yeo Johnson', YeoJohnsonTransformer(variables=NUMERICALS_YEO_JOHNSON)),\n",
    "    \n",
    "    #==== CODIFICACION DE VARIABLES ====#\n",
    "    #- Categoricas binarias\n",
    "    ('categorical_binary_encoder', OrdinalEncoder(encoding_method='ordered', variables=CATEGORICAL_BINARY)),\n",
    "\n",
    "    #- Categoricas Nominales\n",
    "    ('categorical_encoder', OrdinalEncoder(encoding_method='ordered', variables=CATEGORICAL_NOMINAL)),\n",
    "    \n",
    "    #==== Escalado ====# \n",
    "    ('scaler', MinMaxScaler()),\n",
    "    \n",
    "    #==== Entrenamiento del modelo con Lasso ====#\n",
    "    ('SVC', SVC()),\n",
    "])\n",
    "\n",
    "dataX = dataX[FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['titanicPipeline.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanicPipeline.fit(dataX, dataY)\n",
    "dataTest = dataTest[FEATURES]\n",
    "\n",
    "preds = titanicPipeline.predict(dataTest)\n",
    "joblib.dump(titanicPipeline, 'titanicPipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
